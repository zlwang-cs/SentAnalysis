run:
  tag:

  device: cpu
  random_seed: 12345

  batch_size: 2
  total_iter: 100
  save_per_iter: 10
  num_workers: 4

  learning_rate: 0.01
  learning_rate_decay: 0.99
  learning_rate_decay_step: 10

dataset:
  path: data/IMDB-test/
  category: 2

model:
  name: BertBasedModel

  bert:
    weight_dir: /home/wangzilong/Documents/Code/DocStruct/data/bert-weight/bert-large-uncased-whole-word-masking
#    weight_dir: /mnt/lustre/wangzilong/Projects/DocStruct/data/bert-weight/bert-large-uncased-whole-word-masking
    freeze: true

  lstm:
    hidden_size: 1024

  fc: 512

loss:
  func: CrossEntropy

eval:
  func: F1
